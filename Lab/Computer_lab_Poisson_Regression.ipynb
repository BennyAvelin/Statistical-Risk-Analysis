{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlYA0IRh1sDS"
   },
   "source": [
    "# Introduction\n",
    "The Poisson regression model belongs to a class of models called generlized linear models. In a generlized linear model (GLM), the mean of the response, $\\mu$, is modelled as a monotonic (nonlinear) transformation of the explanatory variables, $g(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_p x_p)$. The inverse of the transformation $g$ is called the *canonical link function*. In Poisson regression this function is the log function, but in other GLMs different link functions are used. Also, the response may take different distributions, such as the normal or the binomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "loAS5UgW2iME"
   },
   "source": [
    "# Reading data into python\n",
    "First we import the pandas package (Pandas stands for panel datas), more info can be found at Pandas website www.pandas.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7oQAIYyX-Vu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nwI4NBN2y2_"
   },
   "source": [
    "The csv (comma separated values) file is dat5007.csv and is delimited with \";\". We can use the pandas function read_table to load the data into the variable df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuTIHWc5Ykij"
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"dat5007.csv\",sep=\";\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "4J6vxyY8uxuJ",
    "outputId": "fc4412cf-17fd-4597-8763-715cbefa69ff"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMzJm5mi2_-L"
   },
   "source": [
    "Now, some of the columns have bad values, like spaces and thus pandas cannot see that the column is a numeric value, we can force this to happen using the to_numeric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jruIO8q_Z70Y"
   },
   "outputs": [],
   "source": [
    "df['Varav svårt skadade'] = pd.to_numeric(df['Varav svårt skadade'],errors='coerce')\n",
    "df['Bensinleveranser (1000 m3)'] = pd.to_numeric(df['Bensinleveranser (1000 m3)'],errors='coerce')\n",
    "df['Dödade per 100 000 Invånare'] = pd.to_numeric(df['Dödade per 100 000 Invånare'],errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-RuPnt-83ROa"
   },
   "source": [
    "A final check confirms that all columns are now numeric i.e. float64 (64 bit floating point value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "iBafruZD1Vaz",
    "outputId": "375ff451-a487-4b2d-f3c9-250505f8ab2d"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXkrdsXm3Zpi"
   },
   "source": [
    "The csv file contains some extra columns that are of no use, so lets drop those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZptWZcax1Ws6"
   },
   "outputs": [],
   "source": [
    "df = df.drop(labels=[\"Unnamed: 9\",\"Unnamed: 10\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPBuu2C_3f1O"
   },
   "source": [
    "The df variable now contains a Pandas dataframe which contains all the data, we can take a look at that data using the head function, the value we specify tells pandas how many lines we want to preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "v96BXuGM1f_S",
    "outputId": "276f47b3-694c-4842-e91d-0bfc9e79384e"
   },
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Esr4eRLW3zp5"
   },
   "source": [
    "# Visualizations\n",
    "Try plotting the number of people killed vs. number of cars and the petrol consumption. Do you see any connection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "09E0FZ-j1l67",
    "outputId": "1b243c58-e9c7-44b2-ca29-bf3f904f0b73"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df['År'],df['Dödade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "B9hvt3L44JAk",
    "outputId": "d31bcd65-2ff2-4343-e13f-6cfc3b357b0f"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['År'],df['Bilar i trafik vid årets slut (1000)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "vanOPTa94Sk7",
    "outputId": "191c7eab-ff75-482b-8a89-bcf6e9f39bbc"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['År'],df['Bensinleveranser (1000 m3)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MHfa9-64iLM"
   },
   "source": [
    "From the plot it can be seen that the trend of increasing killed is broken around year 1965. And from year 1970 the number starts to decrease. Why did the number of people killed increase in years 1950-1965? What was the reason for the brake of the increasing trend? (Hint: right-side driving (1967), front seat-belts in new cars (1969), mandatory use of front seat-belts (1975))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_BcpGdo44-W"
   },
   "source": [
    "# The Poisson regression model\n",
    "Consider a sequence of count data, $n_i$, $i=1,\\ldots, k$, for some event, i.e. the number of perished in traffic accidents in a year. This count data is assumed to be observations from random variables $N_i \\in \\text{Po}(\\mu_i)$, (called responses or dependent variables) with mean value $\\mu_i = \\mu_i(x_{i1}, \\ldots , x_{ip})$. The variables, $x_{i1}, . . . , x_{ip}$, are called explanatory variables and are assumed to measure factors that influence the count data.\n",
    "We restrict $\\mu_i$ to be a log-linear function,\n",
    "$$\\mu_i = \\exp(\\beta_0 + \\beta_1 x_{i1} + \\ldots + \\beta_p x_{ip}).$$\n",
    "Thus the probability that $N_i = n$ is,\n",
    "$$\n",
    "  P(N_i = n) = \\frac{e^{-\\mu_i} \\mu_i^n}{n!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LuhLmGw35_2C"
   },
   "source": [
    "# Poisson regression of traffic data\n",
    "\n",
    "We will now try to fit the Poisson regression model to the traffic data of the number of people killed in road accidents. Above, we could see that there was a break in the trend of increasing number people killed around year 1965-1975, mainly because of the improvement in car safety due to the use of safety belts. Because of this it seems reasonable introduce an explanatory variable that captures this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00Y2iO5Y4aaD"
   },
   "outputs": [],
   "source": [
    "df['Säkerhetsbälte'] = (df['År'] > 1975)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljZ0AqlZOUo3"
   },
   "source": [
    "## Removing NaNs\n",
    "Usually it is prudent to remove the NaN (Not a Number) in some way, usually it is because data is missing, sometimes we did something wrong in transforming the data or reading the data. In this case it is simply missing data. There are two rows at the end with no data (probably the csv is formatted incorrectly at the end. Furthermore Severely injured and Petrol deliveries (Svårt skadade & Bensinleveranser) starts from 1956 and forwards, so lets drop the na's. This will give us only a few years of data loss at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W75FW0DNOQuU"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "F_OipDam-h5B",
    "outputId": "3753ddbd-3f34-45c7-d2ad-3e692f2fa9ee"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VS0bgTeQ2iI"
   },
   "source": [
    "As showed in the computer example in the previous lecture, the Poissonregression is part of GLM (Generalized Linear Model) which is provided by the statsmodels package. We start with the customary imports (please see the documentation at https://www.statsmodels.org/stable/index.html for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "A7_IFmvv_nCE",
    "outputId": "8b82faa6-2c7e-4f36-ae9e-5183ba0e2460"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCZtiolsRMEw"
   },
   "source": [
    "Lets start with building a simple model, number of killed vs the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBqievnjBeTP"
   },
   "outputs": [],
   "source": [
    "mod1 = smf.glm(formula=\"Dödade ~ År\",\n",
    "               data=df,\n",
    "               family=sm.families.Poisson()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "9JvUMIfhHqCV",
    "outputId": "8c00d530-e9fd-439e-a771-54adeb7fcf0c"
   },
   "outputs": [],
   "source": [
    "mod1.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r11ZMJPNCA3h"
   },
   "outputs": [],
   "source": [
    "predictions1 = mod1.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "SWo6lvmACJhJ",
    "outputId": "acdd6ed4-8cfd-4ae1-9698-4c52f53c4d11"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['År'],df['Dödade'])\n",
    "plt.scatter(df['År'],predictions1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biO3fIAxSEBn"
   },
   "source": [
    "As we can see above, the year alone does not seem to capture the curve. Let us try some more explanatory variables. But before that let us do something which is essential for statsmodels, i.e. that the column names does not contain spaces and (). We can do that by looping over all column names and replacing the spaces with _ and (,) with _. This type of for loop is called a list comprehension, see https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3w9_9MuDHjB"
   },
   "outputs": [],
   "source": [
    "df.columns = [col.replace(' ','_') for col in df.columns]\n",
    "df.columns = [col.replace('(','_').replace(')','_') for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FtpytkxETNRI"
   },
   "source": [
    "Lets try to include Cars at the end of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOb2tp1iCWZg"
   },
   "outputs": [],
   "source": [
    "mod2 = smf.glm(formula=\"Dödade ~ År + Bilar_i_trafik_vid_årets_slut__1000_\",\n",
    "               data=df,\n",
    "               family=sm.families.Poisson()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "rmjcJ2k3FugJ",
    "outputId": "0157c202-9dad-4f82-da5a-e32ed8a7639d"
   },
   "outputs": [],
   "source": [
    "mod2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nYnyZ8BCf8I"
   },
   "outputs": [],
   "source": [
    "predictions2 = mod2.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "02N7RRA3CmOm",
    "outputId": "bff6b833-1dbb-4a47-c149-5f0adbeaf9fc"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['År'],df['Dödade'])\n",
    "plt.scatter(df['År'],predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgOyvPfZTeGX"
   },
   "source": [
    "This looks much better, but lets see if we can do more, lets try adding Säkherhetsbälte (Seatbelt) and Högertrafik (Right traffic) as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVTYWaj7CnI-"
   },
   "outputs": [],
   "source": [
    "df['Högertrafik'] = (df['År'] > 1969)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHqLYMQnGo-B"
   },
   "outputs": [],
   "source": [
    "# You try to write the code\n",
    "\n",
    "mod3 = smf.glm(formula=\"\",\n",
    "               data=df,\n",
    "               family=sm.families.Poisson()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "id": "qfL1gMnJGtID",
    "outputId": "c9eee195-1f7f-45a5-b497-6139ec55812e"
   },
   "outputs": [],
   "source": [
    "mod3.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNrLl372GvxD"
   },
   "outputs": [],
   "source": [
    "predictions3 = mod3.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "Y-lxZSmpG5hh",
    "outputId": "40238af4-977e-4c56-9682-1918e471819f"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['År'],df['Dödade'])\n",
    "plt.scatter(df['År'],predictions3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNCJ0ugFT345"
   },
   "source": [
    "Now we are getting very close, lets see what happens when we add the amount of petrol consumption (Assuming that the mean fuel consumption of a car has been constant over the years — a 1970-year model of a Volvo used about 10l per 100 km which is approximately the same as for a model from, say year 2000. However, the engine of the model from 2000 probably has more horsepower.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "7mHYv5coUUw7",
    "outputId": "3f699a24-4739-4166-ab39-060b37f48502"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time for you to do the work\n",
    "* Write the code to:\n",
    "    * Fit the model and store into variable mod4\n",
    "    * Print the model summary\n",
    "    * Do a scatter plot with the true values and the predicted values as you have seen for mod1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSRqPokCUu3J"
   },
   "source": [
    "Does it look familiar? Did we do any better with that information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idbxTs4UU40o"
   },
   "source": [
    "# Model selection - deviance\n",
    "It is not always easy to decide, just by looking at a plot, which model to choose. Even though adding more variables improves the fit, it also increases the uncertainty of the estimates. One method to choose complexity of the model is to use the deviance and a hypothesis test. Let $\\beta^\\ast_{\\bf p} = (\\beta^\\ast_0,\\beta^\\ast_1,\\ldots,\\beta^\\ast_p)$ be the ML estimates of the model parameters $\\beta_0,\\beta_1,\\ldots,\\beta_p$ of the full model with p explanatory variables and $\\beta^\\ast_{\\bf q}$ the estimates of a simpler model where only q (where q < p) of the explanatory variables have been used. Then for large k, and under suitable regularity conditions, the deviance\n",
    "$$\n",
    "  \\text{DEV} = 2 (l(\\beta^\\ast_{\\bf p}) - l(\\beta^\\ast_{\\bf q}))\n",
    "$$\n",
    "is approximately $\\chi^2(p-q)$ distributed if the less complex model is true. Thus, it is pos- sible to test if the simpler model can be rejected compared to the full model. Quantiles can be found from tables or by **scipy.stats.chi2.ppf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sBWNUc7hGdX"
   },
   "source": [
    "Thus if $\\text{DEV} > \\chi^2_\\alpha (p-q)$, the difference between log-likelihoods cannot be explained by the statistical variability and hence the simpler model should be rejected. In other words, the more complex model fits data significantly better.\n",
    "\n",
    "Let us compute this using Eq. (7.14) from the book i.e.\n",
    "$$\n",
    "  \\text{DEV} = 2 \\sum_{i=1}^k n_i (\\ln(\\mu^\\ast_{iC})-\\ln(\\mu^\\ast_{iS})\n",
    "$$\n",
    "In the above the C corresponds to complex and S corresponds to simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "FANjhxRgG73H",
    "outputId": "57c553ec-eaec-46b3-edfe-adeb2ddefc51"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "2*np.sum(df['Dödade']*np.log(predictions2)-df['Dödade']*np.log(predictions1))\n",
    "# For you who are not so familiar with numpy, the np.log is just the \n",
    "# natural logarithm applied to each element in the array.\n",
    "# Also all multiplication is elementwise, so its like .* in Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRCARjNGEogx"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "# ss.chi2.ppf\n",
    "# ppf(q, df, loc=0, scale=1)\n",
    "# Percent point function (inverse of cdf — percentiles).\n",
    "# ss.chi2.ppf(q=1-alpha,df=df) represents a the alpha quantile of a chi2 r.v. \n",
    "# with df degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0SRSj7uFQBy"
   },
   "source": [
    "Use the above mentioned `ss.chi2.ppf` to compute the quantile for comparing `mod1` to `mod2` with the deviance computation above. Can we reject the simpler model that only uses Year in favor of a model that uses Year and number of cars?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LkKV-DuGFrJo"
   },
   "source": [
    "### More model selection\n",
    "Do the same for `mod2` vs `mod3` and `mod3` vs `mod4`, what is your final conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Is the Poisson regression model doing a good job of describing the number of people killed in traffic?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Computer lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
